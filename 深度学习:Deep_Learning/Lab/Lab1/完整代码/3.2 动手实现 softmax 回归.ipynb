{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84b1b1ee-9ec9-476e-9b14-70e9c047103d",
   "metadata": {},
   "source": [
    "#  问题：利用torch.nn实现 softmax 回归在Fashion-MNIST数据集上进行训练和测试，并从loss，训练集以及测试集上的准确率等多个角度对结果进行分析\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580f73af-4704-460c-9284-4e853ab2e03a",
   "metadata": {},
   "source": [
    "利用 torch.nn 实现 Softmax 回归模型在 Fashion-MNIST 数据集上进行训练和测试可以通过高层次的模块更加方便地进行操作。接下来将分步骤介绍如何使用 torch.nn 实现 Softmax 回归模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bd01f7-56d7-419d-87b3-2fb81b75e94d",
   "metadata": {},
   "source": [
    "# 数据集加载与预处理\n",
    "使用 torchvision 加载 Fashion-MNIST 数据集，并对数据进行标准化处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8ffa347-b70a-4106-b9ad-8ea38078f881",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# 数据预处理，标准化到 [-1, 1] 之间\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# 加载训练和测试集\n",
    "train_dataset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03762a85-958e-462b-9aab-9b9abc79c773",
   "metadata": {},
   "source": [
    "# 构建 Softmax 回归模型\n",
    "使用 torch.nn 来定义 Softmax 回归模型，这里使用一个全连接层来实现线性变换，再通过 softmax 函数进行归一化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f476e2d-9e45-46de-84cf-31beea524b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxRegression(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(SoftmaxRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, num_classes)  # 输入层和输出层\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out  # 不需要手动加 softmax，后面会结合损失函数自动处理\n",
    "\n",
    "# 初始化模型\n",
    "input_size = 28 * 28  # 图片尺寸 28x28\n",
    "num_classes = 10  # Fashion-MNIST 数据集有 10 个类别\n",
    "model = SoftmaxRegression(input_size, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625575ad-9714-4281-8538-993b753bc353",
   "metadata": {},
   "source": [
    "# 定义损失函数和优化器\n",
    "使用交叉熵损失函数 nn.CrossEntropyLoss()，它会自动将 logits 应用 softmax。优化器使用随机梯度下降（SGD）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5527a3d6-912f-4e18-94b4-d997846a7ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()  # 交叉熵损失\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)  # 随机梯度下降优化器"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b717dd15-431f-494b-b62f-de09adfc50d8",
   "metadata": {},
   "source": [
    "# 训练模型\n",
    "在训练过程中，会将每个批次的数据送入模型，计算损失，并通过反向传播更新参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "096feae0-58cd-4bde-a337-cc27a05b990a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.6795, Accuracy: 0.7760\n",
      "Epoch [2/100], Loss: 0.5177, Accuracy: 0.8218\n",
      "Epoch [3/100], Loss: 0.4851, Accuracy: 0.8335\n",
      "Epoch [4/100], Loss: 0.4681, Accuracy: 0.8390\n",
      "Epoch [5/100], Loss: 0.4560, Accuracy: 0.8434\n",
      "Epoch [6/100], Loss: 0.4477, Accuracy: 0.8467\n",
      "Epoch [7/100], Loss: 0.4411, Accuracy: 0.8486\n",
      "Epoch [8/100], Loss: 0.4354, Accuracy: 0.8508\n",
      "Epoch [9/100], Loss: 0.4315, Accuracy: 0.8516\n",
      "Epoch [10/100], Loss: 0.4272, Accuracy: 0.8535\n",
      "Epoch [11/100], Loss: 0.4243, Accuracy: 0.8539\n",
      "Epoch [12/100], Loss: 0.4215, Accuracy: 0.8555\n",
      "Epoch [13/100], Loss: 0.4191, Accuracy: 0.8565\n",
      "Epoch [14/100], Loss: 0.4170, Accuracy: 0.8564\n",
      "Epoch [15/100], Loss: 0.4148, Accuracy: 0.8568\n",
      "Epoch [16/100], Loss: 0.4127, Accuracy: 0.8582\n",
      "Epoch [17/100], Loss: 0.4111, Accuracy: 0.8586\n",
      "Epoch [18/100], Loss: 0.4095, Accuracy: 0.8591\n",
      "Epoch [19/100], Loss: 0.4078, Accuracy: 0.8596\n",
      "Epoch [20/100], Loss: 0.4066, Accuracy: 0.8597\n",
      "Epoch [21/100], Loss: 0.4054, Accuracy: 0.8608\n",
      "Epoch [22/100], Loss: 0.4038, Accuracy: 0.8610\n",
      "Epoch [23/100], Loss: 0.4029, Accuracy: 0.8615\n",
      "Epoch [24/100], Loss: 0.4018, Accuracy: 0.8617\n",
      "Epoch [25/100], Loss: 0.4008, Accuracy: 0.8621\n",
      "Epoch [26/100], Loss: 0.3994, Accuracy: 0.8621\n",
      "Epoch [27/100], Loss: 0.3983, Accuracy: 0.8628\n",
      "Epoch [28/100], Loss: 0.3976, Accuracy: 0.8629\n",
      "Epoch [29/100], Loss: 0.3967, Accuracy: 0.8631\n",
      "Epoch [30/100], Loss: 0.3962, Accuracy: 0.8633\n",
      "Epoch [31/100], Loss: 0.3950, Accuracy: 0.8635\n",
      "Epoch [32/100], Loss: 0.3943, Accuracy: 0.8642\n",
      "Epoch [33/100], Loss: 0.3936, Accuracy: 0.8639\n",
      "Epoch [34/100], Loss: 0.3930, Accuracy: 0.8642\n",
      "Epoch [35/100], Loss: 0.3924, Accuracy: 0.8643\n",
      "Epoch [36/100], Loss: 0.3918, Accuracy: 0.8648\n",
      "Epoch [37/100], Loss: 0.3912, Accuracy: 0.8649\n",
      "Epoch [38/100], Loss: 0.3906, Accuracy: 0.8645\n",
      "Epoch [39/100], Loss: 0.3899, Accuracy: 0.8653\n",
      "Epoch [40/100], Loss: 0.3889, Accuracy: 0.8659\n",
      "Epoch [41/100], Loss: 0.3888, Accuracy: 0.8662\n",
      "Epoch [42/100], Loss: 0.3883, Accuracy: 0.8652\n",
      "Epoch [43/100], Loss: 0.3876, Accuracy: 0.8666\n",
      "Epoch [44/100], Loss: 0.3871, Accuracy: 0.8664\n",
      "Epoch [45/100], Loss: 0.3870, Accuracy: 0.8667\n",
      "Epoch [46/100], Loss: 0.3858, Accuracy: 0.8673\n",
      "Epoch [47/100], Loss: 0.3856, Accuracy: 0.8659\n",
      "Epoch [48/100], Loss: 0.3852, Accuracy: 0.8671\n",
      "Epoch [49/100], Loss: 0.3848, Accuracy: 0.8668\n",
      "Epoch [50/100], Loss: 0.3844, Accuracy: 0.8670\n",
      "Epoch [51/100], Loss: 0.3841, Accuracy: 0.8671\n",
      "Epoch [52/100], Loss: 0.3836, Accuracy: 0.8673\n",
      "Epoch [53/100], Loss: 0.3833, Accuracy: 0.8667\n",
      "Epoch [54/100], Loss: 0.3827, Accuracy: 0.8671\n",
      "Epoch [55/100], Loss: 0.3823, Accuracy: 0.8673\n",
      "Epoch [56/100], Loss: 0.3818, Accuracy: 0.8674\n",
      "Epoch [57/100], Loss: 0.3819, Accuracy: 0.8673\n",
      "Epoch [58/100], Loss: 0.3816, Accuracy: 0.8675\n",
      "Epoch [59/100], Loss: 0.3812, Accuracy: 0.8673\n",
      "Epoch [60/100], Loss: 0.3808, Accuracy: 0.8684\n",
      "Epoch [61/100], Loss: 0.3806, Accuracy: 0.8686\n",
      "Epoch [62/100], Loss: 0.3798, Accuracy: 0.8690\n",
      "Epoch [63/100], Loss: 0.3795, Accuracy: 0.8681\n",
      "Epoch [64/100], Loss: 0.3794, Accuracy: 0.8678\n",
      "Epoch [65/100], Loss: 0.3791, Accuracy: 0.8692\n",
      "Epoch [66/100], Loss: 0.3790, Accuracy: 0.8683\n",
      "Epoch [67/100], Loss: 0.3786, Accuracy: 0.8686\n",
      "Epoch [68/100], Loss: 0.3782, Accuracy: 0.8682\n",
      "Epoch [69/100], Loss: 0.3781, Accuracy: 0.8691\n",
      "Epoch [70/100], Loss: 0.3778, Accuracy: 0.8697\n",
      "Epoch [71/100], Loss: 0.3777, Accuracy: 0.8690\n",
      "Epoch [72/100], Loss: 0.3768, Accuracy: 0.8690\n",
      "Epoch [73/100], Loss: 0.3768, Accuracy: 0.8698\n",
      "Epoch [74/100], Loss: 0.3766, Accuracy: 0.8700\n",
      "Epoch [75/100], Loss: 0.3764, Accuracy: 0.8694\n",
      "Epoch [76/100], Loss: 0.3764, Accuracy: 0.8692\n",
      "Epoch [77/100], Loss: 0.3762, Accuracy: 0.8694\n",
      "Epoch [78/100], Loss: 0.3758, Accuracy: 0.8694\n",
      "Epoch [79/100], Loss: 0.3753, Accuracy: 0.8697\n",
      "Epoch [80/100], Loss: 0.3750, Accuracy: 0.8703\n",
      "Epoch [81/100], Loss: 0.3751, Accuracy: 0.8697\n",
      "Epoch [82/100], Loss: 0.3745, Accuracy: 0.8704\n",
      "Epoch [83/100], Loss: 0.3746, Accuracy: 0.8699\n",
      "Epoch [84/100], Loss: 0.3739, Accuracy: 0.8700\n",
      "Epoch [85/100], Loss: 0.3739, Accuracy: 0.8698\n",
      "Epoch [86/100], Loss: 0.3738, Accuracy: 0.8694\n",
      "Epoch [87/100], Loss: 0.3735, Accuracy: 0.8708\n",
      "Epoch [88/100], Loss: 0.3738, Accuracy: 0.8696\n",
      "Epoch [89/100], Loss: 0.3731, Accuracy: 0.8707\n",
      "Epoch [90/100], Loss: 0.3732, Accuracy: 0.8707\n",
      "Epoch [91/100], Loss: 0.3729, Accuracy: 0.8700\n",
      "Epoch [92/100], Loss: 0.3726, Accuracy: 0.8707\n",
      "Epoch [93/100], Loss: 0.3724, Accuracy: 0.8706\n",
      "Epoch [94/100], Loss: 0.3720, Accuracy: 0.8703\n",
      "Epoch [95/100], Loss: 0.3718, Accuracy: 0.8721\n",
      "Epoch [96/100], Loss: 0.3719, Accuracy: 0.8710\n",
      "Epoch [97/100], Loss: 0.3716, Accuracy: 0.8707\n",
      "Epoch [98/100], Loss: 0.3714, Accuracy: 0.8706\n",
      "Epoch [99/100], Loss: 0.3713, Accuracy: 0.8703\n",
      "Epoch [100/100], Loss: 0.3710, Accuracy: 0.8711\n"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "num_epochs = 100  # 设置训练的次数\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        # 将图片展平成一维向量\n",
    "        images = images.view(-1, 28*28)\n",
    "        \n",
    "        # 前向传播\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # 反向传播和优化\n",
    "        optimizer.zero_grad()  # 梯度清零\n",
    "        loss.backward()  # 反向传播\n",
    "        optimizer.step()  # 更新参数\n",
    "        \n",
    "        # 计算准确率\n",
    "        _, predicted = torch.max(outputs.data, 1)  # 找出最大值所对应的类别\n",
    "        total_correct += (predicted == labels).sum().item()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    accuracy = total_correct / len(train_loader.dataset)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(train_loader):.4f}, Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d04a19d-3025-47b4-9fb4-7c71d684c7ea",
   "metadata": {},
   "source": [
    "# 测试模型\n",
    "训练完成后，在测试集上评估模型，计算损失和准确率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e1d9174-2391-47e7-a609-5cf97ee35cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.4383, Test Accuracy: 0.8410\n"
     ]
    }
   ],
   "source": [
    "# 测试模型\n",
    "def test(model, test_loader):\n",
    "    model.eval()  # 切换到评估模式\n",
    "    total_correct = 0\n",
    "    total_loss = 0\n",
    "    \n",
    "    with torch.no_grad():  # 在测试时不需要计算梯度\n",
    "        for images, labels in test_loader:\n",
    "            images = images.view(-1, 28*28)\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # 计算损失\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # 计算准确率\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    accuracy = total_correct / len(test_loader.dataset)\n",
    "    print(f'Test Loss: {total_loss/len(test_loader):.4f}, Test Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# 测试模型\n",
    "test(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2ad63b-0fff-435d-b793-26d4cad2e8d2",
   "metadata": {},
   "source": [
    "# 分析结果\n",
    "+ Loss: 训练过程中的损失会逐渐下降，表明模型在学习过程中表现良好。\n",
    "+ Accuracy: 训练集和测试集的准确率逐渐提高，表明模型对数据的分类能力在不断增强。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5346ca98-4150-4201-b1eb-e011dbc8dae1",
   "metadata": {},
   "source": [
    "# 总结\n",
    "通过使用 torch.nn 实现 Softmax 回归模型，我在 Fashion-MNIST 数据集上进行了训练和测试。我从损失、训练集准确率和测试集准确率等多个角度分析了模型的表现。通过这种方式，可以快速搭建出一个高效的分类模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c21a0a-0c77-4152-9182-a4bc9a318f46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
