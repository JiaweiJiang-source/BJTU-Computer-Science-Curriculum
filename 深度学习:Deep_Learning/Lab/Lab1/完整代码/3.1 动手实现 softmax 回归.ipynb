{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4935db3-8f6c-4483-a766-63ea516ca278",
   "metadata": {},
   "source": [
    "# 在本次任务中，我们将手动实现 Softmax 回归模型，并使用 PyTorch 的 Tensor 和 NumPy 库在 Fashion-MNIST 数据集上进行训练和测试。我们还会从零实现交叉熵损失函数，并计算训练集和测试集的准确率。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33eece8-f747-4569-bf7a-e22bd43bae7d",
   "metadata": {},
   "source": [
    "# 数据集加载与处理\n",
    "首先，需要下载并加载 Fashion-MNIST 数据集，使用 PyTorch 提供的 torchvision 来处理该数据集。对数据进行标准化处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6633e871-7688-441d-ba01-810b22ea1c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# 数据集加载与预处理\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# 加载训练和测试集\n",
    "train_dataset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92c0221-74bf-47f3-84f8-cb2c5c6370c4",
   "metadata": {},
   "source": [
    "# Softmax 函数与模型定义\n",
    "Softmax 函数是对每个类别的得分进行归一化，使得输出是一个概率分布。将从零实现 Softmax 回归模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "038552f6-69b5-41bd-9019-3e2bc050d185",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 定义 Softmax 回归模型\n",
    "class SoftmaxRegression(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(SoftmaxRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, num_classes)  # 定义线性层\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear(x)  # 线性层的输出\n",
    "        softmax_output = F.softmax(logits, dim=1)  # 应用 softmax 归一化\n",
    "        return softmax_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d505e4de-ab37-4285-a587-c971b68cc518",
   "metadata": {},
   "source": [
    "# 实现交叉熵损失函数\n",
    "交叉熵损失函数可以通过以下公式实现。需要确保输出不会为 0，否则会导致 log(0) 的情况。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "95904d46-25a7-4c34-8b3a-cba235b2ef39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实现交叉熵损失函数\n",
    "def cross_entropy_loss(y_pred, y_true):\n",
    "    epsilon = 1e-12  # 防止 log(0)\n",
    "    y_pred = torch.clamp(y_pred, epsilon, 1. - epsilon)  # 限制 y_pred 在 (epsilon, 1-epsilon) 范围内\n",
    "    y_true_one_hot = torch.zeros(y_pred.shape)\n",
    "    y_true_one_hot[range(len(y_true)), y_true] = 1\n",
    "    loss = -torch.sum(y_true_one_hot * torch.log(y_pred)) / y_pred.shape[0]\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138e5213-de13-49f4-98c4-7859dc7cfe1e",
   "metadata": {},
   "source": [
    "# 模型训练\n",
    "接下来，实现训练函数。在每个 epoch 中，通过前向传播计算损失，反向传播更新权重。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2a177a34-cf7d-47c4-846e-2b37f5d4e9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练模型\n",
    "def train(model, train_loader, learning_rate, num_epochs):\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.0001)  # 调整学习率/使用 model.parameters() 自动优化所有参数\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        total_correct = 0\n",
    "        \n",
    "        for images, labels in train_loader:\n",
    "            images = images.view(-1, 28*28)  # 将图像展平成一维向量\n",
    "            \n",
    "            # 前向传播\n",
    "            outputs = model.forward(images)\n",
    "            \n",
    "            # 计算损失\n",
    "            loss = cross_entropy_loss(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # 反向传播与优化\n",
    "            optimizer.zero_grad()  # 梯度清零\n",
    "            loss.backward()  # 反向传播\n",
    "            optimizer.step()  # 更新参数\n",
    "            \n",
    "            # 计算准确率\n",
    "            predictions = torch.argmax(outputs, dim=1)\n",
    "            total_correct += (predictions == labels).sum().item()\n",
    "        \n",
    "        accuracy = total_correct / len(train_loader.dataset)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(train_loader):.4f}, Accuracy: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "797aa866-a326-43e9-bfd5-6872d2f7280c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 2.0026, Accuracy: 0.3347\n",
      "Epoch [2/100], Loss: 1.5340, Accuracy: 0.5799\n",
      "Epoch [3/100], Loss: 1.3080, Accuracy: 0.6534\n",
      "Epoch [4/100], Loss: 1.1711, Accuracy: 0.6865\n",
      "Epoch [5/100], Loss: 1.0787, Accuracy: 0.7035\n",
      "Epoch [6/100], Loss: 1.0119, Accuracy: 0.7139\n",
      "Epoch [7/100], Loss: 0.9610, Accuracy: 0.7218\n",
      "Epoch [8/100], Loss: 0.9209, Accuracy: 0.7289\n",
      "Epoch [9/100], Loss: 0.8883, Accuracy: 0.7337\n",
      "Epoch [10/100], Loss: 0.8611, Accuracy: 0.7380\n",
      "Epoch [11/100], Loss: 0.8383, Accuracy: 0.7419\n",
      "Epoch [12/100], Loss: 0.8188, Accuracy: 0.7453\n",
      "Epoch [13/100], Loss: 0.8014, Accuracy: 0.7486\n",
      "Epoch [14/100], Loss: 0.7861, Accuracy: 0.7516\n",
      "Epoch [15/100], Loss: 0.7726, Accuracy: 0.7544\n",
      "Epoch [16/100], Loss: 0.7606, Accuracy: 0.7567\n",
      "Epoch [17/100], Loss: 0.7496, Accuracy: 0.7594\n",
      "Epoch [18/100], Loss: 0.7395, Accuracy: 0.7619\n",
      "Epoch [19/100], Loss: 0.7303, Accuracy: 0.7647\n",
      "Epoch [20/100], Loss: 0.7220, Accuracy: 0.7663\n",
      "Epoch [21/100], Loss: 0.7140, Accuracy: 0.7683\n",
      "Epoch [22/100], Loss: 0.7068, Accuracy: 0.7698\n",
      "Epoch [23/100], Loss: 0.7002, Accuracy: 0.7717\n",
      "Epoch [24/100], Loss: 0.6936, Accuracy: 0.7732\n",
      "Epoch [25/100], Loss: 0.6877, Accuracy: 0.7741\n",
      "Epoch [26/100], Loss: 0.6821, Accuracy: 0.7756\n",
      "Epoch [27/100], Loss: 0.6767, Accuracy: 0.7770\n",
      "Epoch [28/100], Loss: 0.6717, Accuracy: 0.7783\n",
      "Epoch [29/100], Loss: 0.6669, Accuracy: 0.7795\n",
      "Epoch [30/100], Loss: 0.6623, Accuracy: 0.7807\n",
      "Epoch [31/100], Loss: 0.6580, Accuracy: 0.7819\n",
      "Epoch [32/100], Loss: 0.6540, Accuracy: 0.7836\n",
      "Epoch [33/100], Loss: 0.6500, Accuracy: 0.7843\n",
      "Epoch [34/100], Loss: 0.6461, Accuracy: 0.7855\n",
      "Epoch [35/100], Loss: 0.6426, Accuracy: 0.7864\n",
      "Epoch [36/100], Loss: 0.6392, Accuracy: 0.7875\n",
      "Epoch [37/100], Loss: 0.6359, Accuracy: 0.7886\n",
      "Epoch [38/100], Loss: 0.6327, Accuracy: 0.7898\n",
      "Epoch [39/100], Loss: 0.6296, Accuracy: 0.7901\n",
      "Epoch [40/100], Loss: 0.6266, Accuracy: 0.7915\n",
      "Epoch [41/100], Loss: 0.6240, Accuracy: 0.7925\n",
      "Epoch [42/100], Loss: 0.6210, Accuracy: 0.7931\n",
      "Epoch [43/100], Loss: 0.6182, Accuracy: 0.7938\n",
      "Epoch [44/100], Loss: 0.6157, Accuracy: 0.7945\n",
      "Epoch [45/100], Loss: 0.6133, Accuracy: 0.7954\n",
      "Epoch [46/100], Loss: 0.6108, Accuracy: 0.7963\n",
      "Epoch [47/100], Loss: 0.6084, Accuracy: 0.7972\n",
      "Epoch [48/100], Loss: 0.6061, Accuracy: 0.7973\n",
      "Epoch [49/100], Loss: 0.6039, Accuracy: 0.7981\n",
      "Epoch [50/100], Loss: 0.6017, Accuracy: 0.7988\n",
      "Epoch [51/100], Loss: 0.5998, Accuracy: 0.7996\n",
      "Epoch [52/100], Loss: 0.5976, Accuracy: 0.8004\n",
      "Epoch [53/100], Loss: 0.5957, Accuracy: 0.8008\n",
      "Epoch [54/100], Loss: 0.5936, Accuracy: 0.8013\n",
      "Epoch [55/100], Loss: 0.5918, Accuracy: 0.8018\n",
      "Epoch [56/100], Loss: 0.5900, Accuracy: 0.8024\n",
      "Epoch [57/100], Loss: 0.5883, Accuracy: 0.8028\n",
      "Epoch [58/100], Loss: 0.5865, Accuracy: 0.8036\n",
      "Epoch [59/100], Loss: 0.5848, Accuracy: 0.8038\n",
      "Epoch [60/100], Loss: 0.5831, Accuracy: 0.8044\n",
      "Epoch [61/100], Loss: 0.5815, Accuracy: 0.8052\n",
      "Epoch [62/100], Loss: 0.5799, Accuracy: 0.8055\n",
      "Epoch [63/100], Loss: 0.5785, Accuracy: 0.8060\n",
      "Epoch [64/100], Loss: 0.5770, Accuracy: 0.8065\n",
      "Epoch [65/100], Loss: 0.5754, Accuracy: 0.8068\n",
      "Epoch [66/100], Loss: 0.5740, Accuracy: 0.8075\n",
      "Epoch [67/100], Loss: 0.5726, Accuracy: 0.8079\n",
      "Epoch [68/100], Loss: 0.5713, Accuracy: 0.8084\n",
      "Epoch [69/100], Loss: 0.5699, Accuracy: 0.8084\n",
      "Epoch [70/100], Loss: 0.5685, Accuracy: 0.8090\n",
      "Epoch [71/100], Loss: 0.5672, Accuracy: 0.8091\n",
      "Epoch [72/100], Loss: 0.5659, Accuracy: 0.8095\n",
      "Epoch [73/100], Loss: 0.5648, Accuracy: 0.8101\n",
      "Epoch [74/100], Loss: 0.5635, Accuracy: 0.8102\n",
      "Epoch [75/100], Loss: 0.5622, Accuracy: 0.8108\n",
      "Epoch [76/100], Loss: 0.5610, Accuracy: 0.8110\n",
      "Epoch [77/100], Loss: 0.5600, Accuracy: 0.8114\n",
      "Epoch [78/100], Loss: 0.5587, Accuracy: 0.8119\n",
      "Epoch [79/100], Loss: 0.5576, Accuracy: 0.8120\n",
      "Epoch [80/100], Loss: 0.5565, Accuracy: 0.8124\n",
      "Epoch [81/100], Loss: 0.5555, Accuracy: 0.8127\n",
      "Epoch [82/100], Loss: 0.5546, Accuracy: 0.8131\n",
      "Epoch [83/100], Loss: 0.5535, Accuracy: 0.8134\n",
      "Epoch [84/100], Loss: 0.5524, Accuracy: 0.8137\n",
      "Epoch [85/100], Loss: 0.5514, Accuracy: 0.8139\n",
      "Epoch [86/100], Loss: 0.5504, Accuracy: 0.8144\n",
      "Epoch [87/100], Loss: 0.5496, Accuracy: 0.8148\n",
      "Epoch [88/100], Loss: 0.5485, Accuracy: 0.8151\n",
      "Epoch [89/100], Loss: 0.5476, Accuracy: 0.8151\n",
      "Epoch [90/100], Loss: 0.5467, Accuracy: 0.8154\n",
      "Epoch [91/100], Loss: 0.5456, Accuracy: 0.8156\n",
      "Epoch [92/100], Loss: 0.5448, Accuracy: 0.8162\n",
      "Epoch [93/100], Loss: 0.5439, Accuracy: 0.8165\n",
      "Epoch [94/100], Loss: 0.5431, Accuracy: 0.8167\n",
      "Epoch [95/100], Loss: 0.5424, Accuracy: 0.8172\n",
      "Epoch [96/100], Loss: 0.5415, Accuracy: 0.8173\n",
      "Epoch [97/100], Loss: 0.5405, Accuracy: 0.8177\n",
      "Epoch [98/100], Loss: 0.5396, Accuracy: 0.8178\n",
      "Epoch [99/100], Loss: 0.5390, Accuracy: 0.8183\n",
      "Epoch [100/100], Loss: 0.5383, Accuracy: 0.8186\n"
     ]
    }
   ],
   "source": [
    "# 初始化模型并开始训练\n",
    "model = SoftmaxRegression(28*28, 10)  # 输入大小为 28x28，类别数量为 10\n",
    "train(model, train_loader, learning_rate=0.1, num_epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606bbe87-6c2b-4562-877f-e89f32545869",
   "metadata": {},
   "source": [
    "# 测试模型\n",
    "在训练完成后，需要在测试集上评估模型的表现，计算损失和准确率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4480f11b-faa2-4e79-8426-bc7e494203cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.5606, Test Accuracy: 0.8051\n"
     ]
    }
   ],
   "source": [
    "# 模型测试\n",
    "def test(model, test_loader):\n",
    "    total_correct = 0\n",
    "    total_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.view(-1, 28*28)  # 将图像展平成一维向量\n",
    "            \n",
    "            # 前向传播\n",
    "            outputs = model.forward(images)\n",
    "            \n",
    "            # 计算损失\n",
    "            loss = cross_entropy_loss(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # 计算准确率\n",
    "            predictions = torch.argmax(outputs, dim=1)\n",
    "            total_correct += (predictions == labels).sum().item()\n",
    "    \n",
    "    accuracy = total_correct / len(test_loader.dataset)\n",
    "    print(f'Test Loss: {total_loss/len(test_loader):.4f}, Test Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# 测试模型\n",
    "test(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce57263-3d51-4359-861c-ded69963ebd9",
   "metadata": {},
   "source": [
    "# 分析结果\n",
    "+ Loss: 训练过程中的损失会逐渐减小，表明模型在逐渐拟合训练数据。\n",
    "+ Accuracy: 训练和测试的准确率会逐渐提高，并最终达到一定的稳定值，表明模型能正确分类大部分样本。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be91806-2552-402a-89eb-901948472c62",
   "metadata": {},
   "source": [
    "# 总结\n",
    "通过从零实现 Softmax 回归模型，并手动实现交叉熵损失函数，我们成功在 Fashion-MNIST 数据集上训练了模型，并测试了其表现。通过不断优化模型参数，模型的损失逐渐降低，准确率逐渐提高，最终能较好地对图像数据进行分类。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
